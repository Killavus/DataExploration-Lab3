{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multinomial, normal\n",
    "\n",
    "# TrivialCovariances = All Covariances are Eye Matrices, it simplifies the process a lot\n",
    "# (1 x K) -> (K x d) -> (K x d x d) -> N -> Bool -> (d x N, 1 x N)\n",
    "def SamplesFromGaussianMixture(Probs, Means, CovarianceMatrices, SampleCount, TrivialCovariances=False, Precision=np.float_, ChoicesPrecision=np.int_):\n",
    "  MixtureCount = Probs.shape[0]  \n",
    "  Dimension    = Means.shape[1]\n",
    "  CholeskyMatrices = CovarianceMatrices\n",
    "  if not TrivialCovariances:\n",
    "      CholeskyMatrices = np.linalg.cholesky(CovarianceMatrices) # K x d x d\n",
    "    \n",
    "  # Means - K x d\n",
    "  # CholeskyMatrices - # K x d x d\n",
    "  \n",
    "  ResultSet = np.empty(shape=(Dimension, SampleCount), dtype=Precision) # d x N\n",
    "  Choices = np.zeros(SampleCount, dtype=ChoicesPrecision)\n",
    "\n",
    "  MixturesToSample = multinomial(SampleCount, Probs)\n",
    "  GeneratedSamples = 0\n",
    "  for MixtureInd in range(MixtureCount):\n",
    "     Count = MixturesToSample[MixtureInd]\n",
    "     ZMatrix = normal(size=(Dimension, Count))\n",
    "     if not TrivialCovariances:\n",
    "       ZMatrix = np.dot(CholeskyMatrices[MixtureInd], ZMatrix)\n",
    "     ResultSet[:, GeneratedSamples:(GeneratedSamples + Count)] = ZMatrix + Means[MixtureInd].reshape(Means[MixtureInd].shape[0], 1)\n",
    "     Choices[GeneratedSamples:(GeneratedSamples + Count)] = MixtureInd\n",
    "     GeneratedSamples += Count\n",
    " \n",
    "  return ResultSet, Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# (d x N) -> K -> ?(d x K) -> (N x K)\n",
    "def HardCMeans(DataSet, ClusterCount, InitialCenters = None, Precision = np.float_):\n",
    "   DataSetSize        = DataSet.shape[1]\n",
    "   Dimension          = DataSet.shape[0]\n",
    "\n",
    "   # Init:\n",
    "   OldClusterCenterMx = None\n",
    "   ClusterCenterMx    = None\n",
    "   \n",
    "   OldClusterAssignMx = None\n",
    "   ClusterAssignMx    = None\n",
    "\n",
    "   # We can provide initial centers:\n",
    "   if InitialCenters is None:\n",
    "      print 'Initial Centers Randomized'\n",
    "      InitialCenterIndices = randint(0, DataSetSize, ClusterCount)\n",
    "      ClusterCenterMx      = np.array(DataSet[:,InitialCenterIndices], copy=True)\n",
    "   else:\n",
    "      print 'Initial Centers Provided'\n",
    "      ClusterCenterMx = np.array(InitialCenters, copy=True)    \n",
    "\n",
    "   RowIndices     = np.arange(0, DataSetSize)\n",
    "   DSizeRankOnes  = np.ones(DataSetSize)\n",
    "   DistanceMatrix = np.empty(shape=(DataSet.shape[1], ClusterCount), dtype=Precision)\n",
    "\n",
    "   while (((OldClusterAssignMx is None) or ((OldClusterAssignMx != ClusterAssignMx).nnz != 0)) and \n",
    "      ((OldClusterCenterMx is None) or not np.array_equal(OldClusterCenterMx, ClusterCenterMx))):\n",
    "      print \"Iteration...\"\n",
    "      OldClusterAssignMx = ClusterAssignMx\n",
    "      OldClusterCenterMx = ClusterCenterMx\n",
    "        \n",
    "      # Computing Distance Matrix:\n",
    "      np.dot(DataSet.T, ClusterCenterMx, out=DistanceMatrix)\n",
    "      DistanceMatrix *= -2\n",
    "      DistanceMatrix += np.sum(ClusterCenterMx ** 2, axis=0, keepdims=True)\n",
    "    \n",
    "      # Computing Closest Center:\n",
    "      BestAssignments = np.argmin(DistanceMatrix, axis=1)\n",
    "\n",
    "      # Computing Assignment Matrix\n",
    "      ClusterAssignMx = csr_matrix((DSizeRankOnes, (RowIndices, BestAssignments)), shape=(DataSetSize, ClusterCount))\n",
    "    \n",
    "      # Computing New Centers:\n",
    "      ClusterCenterMx = ClusterAssignMx.T.dot(DataSet.T).T\n",
    "      ClusterCenterMx /= ClusterAssignMx.sum(axis=0)\n",
    "    \n",
    "   return ClusterAssignMx.toarray(), ClusterCenterMx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 1000-dimensional Samples Generated\n",
      "Initial Centers Provided"
     ]
    }
   ],
   "source": [
    "Dim          = 1000\n",
    "SampleSize   = 1000000\n",
    "MixtureCount = 1000\n",
    "MeanOffset   = 10.0\n",
    "\n",
    "Propabilities = np.ones(MixtureCount) / MixtureCount\n",
    "MeanMatrix    = np.ones((MixtureCount, Dim))\n",
    "MeanSteps     = np.arange(0, MixtureCount * MeanOffset, MeanOffset)\n",
    "Means         = MeanMatrix * MeanSteps.reshape(MeanSteps.shape[0], 1)\n",
    "CovMatrices   = np.full((MixtureCount, Dim, Dim), np.eye(Dim))\n",
    "Samples, Groups = SamplesFromGaussianMixture(Propabilities, Means, CovMatrices, SampleSize, True, np.float16, np.uint16)\n",
    "print \"%d %d-dimensional Samples Generated\" % (SampleSize, Dim)\n",
    "\n",
    "# Sensible Centres\n",
    "InitialCentres = np.empty(shape=(Dim, MixtureCount), dtype=np.float16)\n",
    "for Group in range(MixtureCount):\n",
    "    GroupMask = Group == Groups\n",
    "    GroupSize = np.sum(GroupMask)\n",
    "\n",
    "    SummedDims = np.sum(Samples[:, GroupMask], axis=1)\n",
    "    InitialCentres[:, Group] = SummedDims / GroupSize\n",
    "\n",
    "Assignments, UnusedFinalCentres = HardCMeans(Samples, MixtureCount, InitialCentres, np.float16)\n",
    "AssignmentsForm = np.nonzero(Assignments)[1]\n",
    "\n",
    "for Group in range(MixtureCount):\n",
    "    GroupMask = Group == Groups\n",
    "    GroupSize = np.sum(GroupMask)\n",
    "\n",
    "    AssignmentsMask = Group == AssignmentsForm\n",
    "\n",
    "    Error = (np.sum(GroupMask != AssignmentsMask) / float(GroupSize)) * 100.0\n",
    "    print \"Group #%d err percentage: %1.8f\" % (Group + 1, Error)\n",
    "\n",
    "OverallError = (np.sum(Groups != AssignmentsForm) / float(SampleSize)) * 100.0\n",
    "print \"Overall  err percentage: %1.8f\" % (OverallError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000000)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
